{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0NkNIdOUUHN"
   },
   "source": [
    "# HW2- Steam Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1634674196170,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "JKVANiYkZErq",
    "outputId": "dcfef933-0b55-419b-e270-d9b5abc10017"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "''';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moEqNAhjTt2d"
   },
   "source": [
    " This is a dataset of around 21 million user reviews of around 300 different games on Steam: sto importando solo poche righe per lavorarci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_with_time(path, time_fields, n_rows, usecols=None):\n",
    "    '''\n",
    "      This function reads a csv and returns a dataframe considering only the first n_rows rows\n",
    "      and transforming the indicated time_fields from timestamp(seconds) in datetime objects\n",
    "\n",
    "      Arguments\n",
    "      _________\n",
    "        path: str\n",
    "          The path where the file is located\n",
    "        time_fields: List[str]\n",
    "          A list of the fields to be converted in datetime\n",
    "        n_rows: int\n",
    "          The number of rows to be considered\n",
    "        usecols: List[str]\n",
    "          The list of the columns to be loaded      \n",
    "      Returns\n",
    "      _______\n",
    "        a pandas dataframe containing the processed file\n",
    "    '''\n",
    "    \n",
    "    return pd.read_csv(path, header='infer', nrows=n_rows, \n",
    "        parse_dates= [tf for tf in time_fields], date_parser=lambda x: pd.to_datetime(x, unit='s'), usecols=usecols)\n",
    "\n",
    "def hour_in_range(str_hour, range_hour):\n",
    "    '''\n",
    "      Given a string defining an hour and a range of hour as a tuple of that type of string,\n",
    "      the function assert when the given hour is in the range\n",
    "\n",
    "      Arguments\n",
    "      _________\n",
    "        str_hour: str\n",
    "          in the format HH:MM:SS\n",
    "        range_hour: Tuple(str)\n",
    "          a tuple of string in the form (HH:MM:SS, HH:MM:SS) where the first hour is lower than the second\n",
    "    '''\n",
    "    \n",
    "    min_hour, max_hour = range_hour\n",
    "    assert (hour_comparator(min_hour, max_hour) == -1), \"A range is valid only if the first element is lower than the second\"\n",
    "    return (hour_comparator(str_hour, min_hour) * hour_comparator(max_hour, str_hour)) >=0\n",
    "\n",
    "def hour_comparator(str_h1, str_h2):\n",
    "    '''\n",
    "      Compares two string in the format HH:MM:SS and returns an integer value accordingly with their comparison\n",
    "      \n",
    "      Arguments\n",
    "      __________\n",
    "        str_h1: str\n",
    "          in the format HH:MM:SS\n",
    "        str_h2: str\n",
    "          in the format HH:MM:SS\n",
    "      \n",
    "      Returns\n",
    "      _______\n",
    "        An integer representing the comparison between the given strings:\n",
    "          -1  if the first is less then the second\n",
    "           0  if the dates are the same\n",
    "           1  if the first is greater than the second\n",
    "    '''\n",
    "    hh1, mm1, ss1 = map(int,str_h1.split(':'))\n",
    "    hh2, mm2, ss2 = map(int, str_h2.split(':'))\n",
    "    deltas = [hh1-hh2, mm1-mm2, ss1-ss2]\n",
    "    for d in deltas:\n",
    "        if d>0:\n",
    "            return 1\n",
    "        elif d < 0:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def get_range_index(str_hour, ranges):\n",
    "    '''\n",
    "      Given a string hour and a list of hour ranges, the function returns the index of the range\n",
    "      to wich the string hour belongs\n",
    "\n",
    "      Arguments\n",
    "      _________\n",
    "        str_hour: str\n",
    "          in the format HH:MM:SS\n",
    "        ranges: List[Tuple(str)]\n",
    "          List containing hour ranges, so list o tuples of string in the form\n",
    "          (HH:MM:SS, HH:MM:SS) where the first hour is lower than the second\n",
    "      \n",
    "      Return\n",
    "      ______\n",
    "        an integer indicating the index of the range where the hour is\n",
    "    '''\n",
    "    for i in range(len(ranges)):\n",
    "        if hour_in_range(str_hour, ranges[i]):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def transform_in_hour_ranges(df, column, ranges):\n",
    "    '''\n",
    "      Given a dataframe convert the given column of datetime to the index of the range in the given list\n",
    "      where the value belongs\n",
    "\n",
    "      Arguments\n",
    "      _________\n",
    "        df: pd.DataFrame\n",
    "        column: str\n",
    "          the name of a Datetime column of the df\n",
    "        ranges: List[Tuple(str)]\n",
    "          List containing hour ranges, so list o tuples of string in the form\n",
    "          (HH:MM:SS, HH:MM:SS) where the first hour is lower than the second\n",
    "\n",
    "      Return\n",
    "      ______\n",
    "        the df with the given column modified\n",
    "\n",
    "    '''\n",
    "    df[column]=df[column].apply(lambda x: get_range_index(x.strftime('%H:%M:%S'), ranges))\n",
    "    return df\n",
    "\n",
    "\n",
    "# REALLY USED:\n",
    "\n",
    "#read_csv_with_time\n",
    "\n",
    "def get_integer_ranges(ranges):\n",
    "    return [(tuple(int(data) for data in x[0].split(':')), tuple(int(data) for data in x[1].split(':'))) for x in ranges]\n",
    "\n",
    "def get_integer_range_index(tuple_hour, integer_ranges):\n",
    "    \n",
    "    for i in range(len(integer_ranges)):\n",
    "        min_r, max_r = integer_ranges[i]\n",
    "        if tuple_hour >= min_r and tuple_hour <= max_r:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/content/drive/MyDrive/HW2-ADM/steam_reviews.csv'\n",
    "fname = '/content/drive/MyDrive/HW2-ADM/steam_reviews.csv'\n",
    "ts_created = 'timestamp_created'\n",
    "\n",
    "def_ranges = [('06:00:00', '10:59:59'),\n",
    "('11:00:00', '13:59:59'),\n",
    "('14:00:00', '16:59:59'),\n",
    "('17:00:00', '19:59:59'),\n",
    "('20:00:00', '23:59:59'),\n",
    "('00:00:00', '02:59:59'),\n",
    "('03:00:00', '05:59:59')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usefull libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "executionInfo": {
     "elapsed": 66374,
     "status": "ok",
     "timestamp": 1634671082402,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "mqILoTqDZjgz",
    "outputId": "7126ba17-7f37-49a7-f117-9c3e80781211"
   },
   "outputs": [],
   "source": [
    "#df= pd.read_csv('/content/drive/MyDrive/HW2-ADM/steam_reviews.csv',nrows=10000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('steam_reviews.csv',nrows=21000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ1]: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izowx8OkauCN"
   },
   "source": [
    "We can see that there are 23 columns, 8 integer,5 decimal, 4 boolean and 6 of other type.\n",
    "The first one 'Unnamed' can be consider just like an index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2263,
     "status": "ok",
     "timestamp": 1634244260432,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "iDgrdzC-bEVA",
    "outputId": "68a23256-d05a-463e-8c21-a17b723c1da2"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUbzJQE8duEQ"
   },
   "source": [
    "It appears that the variables with missing values ​​are: 'review' (which contains the text itself) , 'author.playtime_at_review' (Author playtime of reviewed app at time of review) ,   ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnK32w4ceJ5h"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#seaborn.heatmap(df)\n",
    "df_kor = df.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_kor, vmin=-1, vmax=1, cmap=\"viridis\", annot=True, linewidth=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDUD-6R9gfFn"
   },
   "source": [
    "Now let's focus on the variables that we consider more interesting. We start with app_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1320,
     "status": "ok",
     "timestamp": 1634496691952,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "zOfRbQ8Lgm2W",
    "outputId": "662ffff6-3c82-4639-ac95-5a2243645f31"
   },
   "outputs": [],
   "source": [
    "#App_name\n",
    "x=df[\"app_name\"].value_counts(normalize=True) #in percentuale le diverse app recensite\n",
    "print(x)\n",
    "names=df[\"app_name\"].unique() #nomi app\n",
    "print(names)\n",
    "label=[\"Tom Clancy's Rainbow Six Siege\",\"Garry's Mod\",\"Rust\" ]\n",
    "\n",
    "#x_1=x[:3:]\n",
    "#print(x_1)\n",
    "\n",
    "#Grafico a torta\n",
    "x.plot.pie() #labels=label)\n",
    "plt.show()\n",
    "\n",
    "#Farei un barpot con quelle \"vere\"\n",
    "plt.bar(names,x)\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqkY2fa_h1Ug"
   },
   "source": [
    "In total there are 315 different apps, the most common are: PLAYERUNKNOWN'S BATTLEGROUNDS (8%),Grand Theft Auto V (5%) and.. (bo va visto sui dati tot).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Giqz-mmWbJ"
   },
   "source": [
    "Now we consider the language. The most common are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1634497634244,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "lQURMq01mb1x",
    "outputId": "8a888d2d-c7c3-43cd-b94d-85a42ca10efb"
   },
   "outputs": [],
   "source": [
    "print(df[\"language\"].value_counts(normalize=True))\n",
    "data=[0.46,0.14,0.11]\n",
    "labels = ['english', 'chinese', 'russian']\n",
    "plt.xticks([1,2,3], labels)\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title(\"Language's barplot\")\n",
    "plt.bar([1,2,3], data)\n",
    "plt.grid(color='#95a5a6', linestyle='--', linewidth=2, axis='y', alpha=0.7)\n",
    "plt.ylim(0.0,1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-tEMm6YpzN6"
   },
   "source": [
    "Recommended and steam_purchase \n",
    "We observe that 92% of review authors recommend the app and 78% of them purchased the app on Steam. But only 72% of the authors give a positive opinion and then actually buy the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1634499541495,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "pa0iP7e8resC",
    "outputId": "c9098695-ec19-4e49-a0a4-12ee2924d5a1"
   },
   "outputs": [],
   "source": [
    "print(df[\"recommended\"].value_counts(normalize=True))\n",
    "\n",
    "print(df[\"steam_purchase\"].value_counts(normalize=True))\n",
    "\n",
    "len(df[  (df.recommended == True) &(df.steam_purchase == True)  ])/ 10000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vE180Jo1vUoZ"
   },
   "source": [
    "\n",
    "author.num_reviews :Number of lifetime app reviews by author\n",
    "Con i dati veri si può fare un commento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 764,
     "status": "ok",
     "timestamp": 1634499802250,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "tDRNRuCJvkpw",
    "outputId": "e8e4154a-a15c-403c-f6b3-9e83e9cc3a15"
   },
   "outputs": [],
   "source": [
    "print(df[\"author.num_reviews\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAUFwhMcx9Ci"
   },
   "source": [
    "# RQ2: Let's explore the dataset by finding simple insights into the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of reviews for each application in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1ZJ8q5HyJf_"
   },
   "outputs": [],
   "source": [
    "new = df[['app_name']]\n",
    "a=new[\"app_name\"].value_counts()\n",
    "app_sort=a.sort_values(ascending=False) #lo salvo perchè serve dopo\n",
    "app_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What applications have the best Weighted Vote Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH9T9qoF6EXm"
   },
   "outputs": [],
   "source": [
    "#In this way  the apps are sorted by  the score and then we can consider the top 5/10 (is up to us).\n",
    "new_1 = df[['app_name','weighted_vote_score'  ]]\n",
    "new_1.sort_values(by='weighted_vote_score',ascending=False)\n",
    "#In this way I compute the average score for each app\n",
    "new_1.groupby('app_name').agg({\"weighted_vote_score\":\"mean\"})\n",
    "#LO lascerei svolto in entrambi i modi, come dicono su slack. Non gredo che agg (aggregate) sia necessario ma non sapevo  farlo senza. Non faccio i commenti perchè tanto i risultati finali saranno diversi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which applications have the most and the least recommendations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1634650682919,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "fD8DLgii6QJR",
    "outputId": "7927aeb9-acc8-4e0b-b492-f7913889e7e2"
   },
   "outputs": [],
   "source": [
    "\n",
    "y=df.groupby('app_name').agg({\"recommended\":\"sum\"})\n",
    "#print(y)\n",
    "\n",
    "y=y.sort_values(by=\"recommended\",ascending=False)\n",
    "#print('the most recommended application is ...... with a total number of recommendations of .....', )\n",
    "y[0:5] #most\n",
    "#print('the worst recommended application is ..... with a total number of recommendations of ....', )\n",
    "#y[-1:] #least\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of these applications were purchased, and how many were given for free?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1634586591610,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "djlptn_N7oX4",
    "outputId": "3490b838-e0c1-453a-b0b4-b007d8c8820a"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(df[\"steam_purchase\"].value_counts(normalize=True))\n",
    "print(df[\"received_for_free\"].value_counts(normalize=True))\n",
    "#Steam purchased: True se l'autore ha comprato l'app su Steam\n",
    "#Received for free: True se ha ricevuto l'app gratis.\n",
    "#non so bene quale vuole, per me il secondo ma boo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK8oLBHB-RhP"
   },
   "source": [
    "# RQ3: Now it's important to understand the preferred time to do reviews.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I'll use the already loaded-in-memory dataset (in the variable df) in order to map every timestamp_created entry from the Datetime format, to a tuple made by the integer value of hour and minutes, once it's done i'll use the obtained column to group by the mapped rows counting the occourrence of every distinct row, i've subsequently used that pd.Series in order to extract the couple (hour, minutes) that maximizes the number of rows, so the number of reviews made in that hour range\n",
    "\n",
    "The results are printed with a formatted string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df = read_csv_with_time(fname, ['timestamp_created'], n_rows=10e6, usecols=['timestamp_created'])\n",
    "\n",
    "# Converting the timestamps in tuples made by hours and minutes\n",
    "timed = df.timestamp_created.apply(lambda x: (x.hour, x.minute))\n",
    "# grouping by values (the tuples of above) and counting the occourrences\n",
    "timed = timed.groupby(timed).count() \n",
    "amax = timed.argmax() # Getting the index of the maximum value\n",
    "\n",
    "# Retrievieng the answers and formatting them...\n",
    "hh, mm = timed.index[amax]\n",
    "n_rev = timed.values[amax]\n",
    "hh = \"{:0>2d}\".format(hh)\n",
    "mm = \"{:0>2d}\".format(mm)\n",
    "\n",
    "print(f\"The most common hour in wich are published the greater part of the reviews is at {hh}:{mm} with {n_rev} reviews published\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function required is the following and returns a pd.Series where the index are the index of the corresponding hour range and the values are the number of reviews made in that range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_bis(ranges, ds=fname, n_rows=1e6):\n",
    "    df = read_csv_with_time(ds, ['timestamp_created'], n_rows, usecols=['timestamp_created'])\n",
    "    ranges_int = get_integer_ranges(ranges)\n",
    "    ranged = df.timestamp_created.apply(lambda x: get_integer_range_index((x.hour, x.minute, x.second), ranges_int))\n",
    "    ranged = ranged.groupby(ranged).count()\n",
    "    return ranged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've used the function above in order to plot by an horizontal bar chart, the number of reviews made for every hour range of the default ranges shown in the table above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = new_bis(def_ranges, n_rows=30e6)\n",
    "plt.figure(figsize=(20,10))\n",
    "ax = ret.plot(kind=\"barh\", color='green')\n",
    "ax.set_title(\"Reviews per hour ranges\")\n",
    "ax.set_ylabel(\"hour ranges\")\n",
    "ax.set_xlabel(\"Num of reviews\")\n",
    "ax.set_yticklabels(def_ranges)\n",
    "ax.grid(b=True, color='grey', linestyle='-.', linewidth=0.5, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vAYkLSO-o9-"
   },
   "outputs": [],
   "source": [
    "#previous code\n",
    "import pandas as pd\n",
    "'''\n",
    "\n",
    "\n",
    "def read_csv_with_time(path, time_fields, n_rows):\n",
    "    return pd.read_csv(path, header='infer', nrows=n_rows, \n",
    "        parse_dates= [tf for tf in time_fields], date_parser=lambda x: pd.to_datetime(x, unit='s'))\n",
    "\n",
    "def hour_in_range(str_hour, range_hour):\n",
    "    min_hour, max_hour = range_hour\n",
    "    return (hour_comparator(str_hour, min_hour) * hour_comparator(max_hour, str_hour)) >=0\n",
    "\n",
    "def hour_comparator(str_h1, str_h2):\n",
    "    \n",
    "        #Compares two string in the format HH:MM:SS and returns:\n",
    "        #    -1 if the first is less then the second\n",
    "        #     0  if the dates are the same\n",
    "        #    1 if the first is greater than the second\n",
    "    \n",
    "    hh1, mm1, ss1 = map(int,str_h1.split(':'))\n",
    "    hh2, mm2, ss2 = map(int, str_h2.split(':'))\n",
    "    deltas = [hh1-hh2, mm1-mm2, ss1-ss2]\n",
    "    for d in deltas:\n",
    "        if d>0:\n",
    "            return 1\n",
    "        elif d < 0:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def get_range_index(str_hour, ranges):\n",
    "    for i in range(len(ranges)):\n",
    "        if hour_in_range(str_hour, ranges[i]):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def transform_in_hour_ranges(df, column, ranges):\n",
    "    df[column]=df[column].apply(lambda x: get_range_index(x.strftime('%H:%M:%S'), ranges))\n",
    "    return df\n",
    "\n",
    "fname = '/content/drive/MyDrive/HW2-ADM/steam_reviews.csv'\n",
    "ts_created = 'timestamp_created'\n",
    "\n",
    "def_ranges = [('06:00:00', '10:59:59'),\n",
    "('11:00:00', '13:59:59'),\n",
    "('14:00:00', '16:59:59'),\n",
    "('17:00:00', '19:59:59'),\n",
    "('20:00:00', '23:59:59'),\n",
    "('00:00:00', '02:59:59'),\n",
    "('03:00:00', '05:59:59')]\n",
    "\n",
    "df = transform_in_hour_ranges(read_csv_with_time(fname, [ts_created], 1000000), ts_created, def_ranges)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "labels = ['pippo' for df in def_ranges]\n",
    "plt.xticks(list(range(len(labels))), labels)\n",
    "#plt.setxticks\n",
    "df.groupby(df.timestamp_created).review_id.count().plot.bar()\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVtj47B5D308"
   },
   "source": [
    "# RQ4 As Steam is a worldwide platform, the reviews can be done in many languages. Let's extract some information about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the top 3 languages used to review applications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH6IIsrqD9kN"
   },
   "outputs": [],
   "source": [
    "lingue=df[\"language\"].value_counts(normalize=True)\n",
    "top=lingue[:3]\n",
    "top_list=list(top.index)\n",
    "print(*(x for x in top_list), sep='\\n')\n",
    "#top five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that receives as parameters both the name of a data set and a list of languages’ names and returns a data frame filtered only with the reviews written in the provided languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5n44py7qEb2e"
   },
   "outputs": [],
   "source": [
    "\n",
    "def filter_language(dataset, languages,col_name):\n",
    "  return dataset.loc[dataset[col_name].isin(languages)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the function created in the previous literal to find what percentage of these reviews (associated with the the top 3 languages) were voted as funny?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11783,
     "status": "ok",
     "timestamp": 1634672021570,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "-UNGmMDD3fX9",
    "outputId": "c1e1b33b-fe41-4748-a827-38e7098105b5"
   },
   "outputs": [],
   "source": [
    "for i in top_list:\n",
    "     print(i+\"   \"+str(round(sum((df['votes_funny']==0) & (df['language']==i))/sum(df['language']==i),2))+\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the function created in the literal “a” to find what percentage of these reviews (associated with the top 3 languages) were voted as helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10476,
     "status": "ok",
     "timestamp": 1634672117666,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "jzts3OcdC6Rf",
    "outputId": "ae7ffc8f-6234-43c4-a1c6-0399a1f745a7"
   },
   "outputs": [],
   "source": [
    "df_1= filter_language(df,top_list,'language') #dati filtrati\n",
    "for i in top_list:\n",
    "  print(i+\"   \"+str(round(sum((df['votes_helpful']!=0) & (df['language']==i))/sum(df['language']==i),2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prcNliAJ3gZt"
   },
   "source": [
    "# RQ5 The reviews' authors are users from the game that provide their opinion on it. Now you can check how often they make reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the top 10 most popular reviewers and the number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "executionInfo": {
     "elapsed": 94978,
     "status": "ok",
     "timestamp": 1634655628889,
     "user": {
      "displayName": "Alessandro Pecchini",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11901581996892479685"
     },
     "user_tz": -120
    },
    "id": "n1ABlGeg4LMm",
    "outputId": "80067de5-6116-4867-8edf-73d3e444df9b"
   },
   "outputs": [],
   "source": [
    "#df= pd.read_csv('/content/drive/MyDrive/HW2-ADM/steam_reviews.csv',nrows=10000000)\n",
    "df_auth = df.groupby('author.steamid').review_id.count().sort_values(ascending=False)\n",
    "df_auth[:10].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What applications did the most popular author review? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRnn_ehG5YKg"
   },
   "outputs": [],
   "source": [
    "from_bigger_reviewer = df[df['author.steamid'] == df_auth[:1].index[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1634655642208,
     "user": {
      "displayName": "Alessandro Pecchini",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11901581996892479685"
     },
     "user_tz": -120
    },
    "id": "Jz4iSYyU8dQ4",
    "outputId": "306301ae-8a31-4ecd-f0dc-f2f0b7dac40a"
   },
   "outputs": [],
   "source": [
    "from_bigger_reviewer['app_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many applications did he purchase, and how many did he get as free? Provide the number (count) and the percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qH1IMHp458JS"
   },
   "outputs": [],
   "source": [
    "free = from_bigger_reviewer[from_bigger_reviewer.received_for_free]\n",
    "n_free = len(free)\n",
    "purchased = from_bigger_reviewer[from_bigger_reviewer.steam_purchase]\n",
    "n_purch = len(purchased)\n",
    "tot = len(from_bigger_reviewer)\n",
    "print(f\"He got for free {n_free} applications ({n_free/tot*100}%) and purchased {n_purch} ({n_purch/tot*100}%) on total of {tot}\")\n",
    "print('   ')\n",
    "print(f\"The author's recommended {len(free['recommended'])} and doesn't recommended {n_free-len(free['recommended'])} application from the ones received for free\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of the applications he purchased reviewed positively, and how many negatively? How about the applications he received for free?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('   ')\n",
    "print(f\" recommended {len(purchased['recommended'])} and doesn't recommended {n_purch-len(purchased['recommended'])} application from the ones purchased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [RQ6] It's time to get information from the updates that a user does to his reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average time (days and minutes) a user lets pass before he updates a review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The average time that pass between the creation and the update of the reviews is: {(df.timestamp_updated - df.timestamp_created).mean(numeric_only=False)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the top 3 authors that usually update their reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['updated'] = df.timestamp_created == df.timestamp_updated\n",
    "grouped = df.groupby(df['author.steamid']).updated.sum().sort_values(ascending=False)\n",
    "auth = grouped[:3].index\n",
    "print(\"The authors that has updated their reviews more often are, in order:\")\n",
    "for a in auth:\n",
    "  print(f\"\\t*{a} with {grouped[a]} updated reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qY_XymYaH6Ge"
   },
   "source": [
    "# RQ7 Of course, calculating probabilities is a job that any Data Scientist must know. Let's compute Some interesting figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-AWty06aGxr"
   },
   "source": [
    "### What’s the probability that a review has a Weighted Vote Score equal to or bigger than 0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3941,
     "status": "ok",
     "timestamp": 1634673249511,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "l_4-d2Q3__pf",
    "outputId": "69505edd-5ff0-4781-e785-ca5b47f22431"
   },
   "outputs": [],
   "source": [
    "#Prob = fav. cases / possible cases\n",
    "p1=sum(df['weighted_vote_score']> 0.5)/df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What’s the probability that a review has at least one vote as funny given that the Weighted Vote Score is bigger than 0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob condizionata\n",
    "\n",
    "intersezione=sum((df['weighted_vote_score']> 0.5)& (df['votes_funny']!=0))/df.shape[0]\n",
    "p2=intersezione/p1\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the probability that “a review has at least one vote as funny” independent of the “probability that a review has a Weighted Vote Score equal or bigger than 0.5”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa= sum(df['votes_funny']!=0)/df.shape[0]\n",
    "pa*p1==intersezione\n",
    "#False, quindi Non sono indipendenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DOaZZ0KLPnX"
   },
   "source": [
    "# RQ8 Every decision you take in a data-based environment should be reinforced with charts, statistical tests and analysis methods to check if a hypothesis is correct or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a significant difference in the Weighted Vote Score of reviews made in Chinese vs the ones made in Russian? Use an appropriate statistical test or technique and support your choicv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2733,
     "status": "ok",
     "timestamp": 1634675835391,
     "user": {
      "displayName": "camilla savarese",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01187100401107976032"
     },
     "user_tz": -120
    },
    "id": "xqFR5dLQLVaf",
    "outputId": "0f3490dc-1be2-441d-e177-bb9d0df6a1e6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "v1=df.loc[df['language'] == 'russian', 'weighted_vote_score']\n",
    "v2=df.loc[df['language'] == 'chinese', 'weighted_vote_score']\n",
    "\n",
    "#!pip3 install  researchpy\n",
    "#import scipy.stats as stats\n",
    "\n",
    "#stats.ttest_ind(df['weighted_vote_score'][df['language'] == 'russian'],\n",
    "                #df['weighted_vote_score'][df['language'] == 'chinese'])\n",
    "stats.ttest_ind(v1,v2)\n",
    "''';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is there a significant difference in the Weighted Vote Score of reviews made in Chinese vs the ones made in Russian? Use an appropriate statistical test or technique and support your choicv1\n",
    "s1=df['weighted_vote_score'][df['language'] == 'russian']\n",
    "s2=df['weighted_vote_score'][df['language'] == 'schinese']\n",
    "s1.describe()\n",
    "s2.describe()\n",
    "#sono abbastanza diverse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grafici per far vedere che non vale la normalità se teniamo gli zeri.\n",
    "import seaborn as sns \n",
    "\n",
    "z1= s1[s1!=0]\n",
    "z2= s2[s2!=0]\n",
    "z2\n",
    "sns.displot(z1)\n",
    "\n",
    "sns.displot(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prendiamo gli zeri: la parte discreta\n",
    "zero_1= s1[s1==0]\n",
    "zero_2=s2[s2==0]\n",
    "\n",
    "#booo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. \n",
    "#Test per la aprte continua\n",
    "stats.ttest_ind(z1,z2)\n",
    "#There is a statistically significant difference in the average score between english and chinese, t= -69, p= 0.00.\n",
    " #If the p-value is smaller than our threshold, then we have evidence against the null hypothesis of equal population means.\n",
    " #The t-test quantifies the difference between the arithmetic means of the two samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indepentent T-test is a parametric test used to test for a statistically significant difference in the means between 2 groups. As with all parametric tests, there are certain conditions that need to be met in order for the test results to be considered reliable. \n",
    "Hp:\n",
    "The two samples are independent: accettabile per costruzione (?)\n",
    "One of the assumptions is that the sampling distribution is normally distributed. N is very big so it's ok.\n",
    "A way to test the assumption is through a visual check (va fatto non ci riuscivo..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import researchpy as rp\n",
    "summary, results = rp.ttest(group1= z1, group1_name= \"Russian\", group2= z2, group2_name= \"Chinese\")\n",
    "print(summary)\n",
    "#farò un commento\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you find any significant relationship between the time that a user lets pass before he updates the review and the Weighted Vote Score? Use an appropriate statistical test or technique and support your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea could be fitted a linear regression, where y=W vote score is the dependent variable and the time is the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=df[ 'weighted_vote_score']\n",
    "t1=np.array(t1)\n",
    "t2=(df.timestamp_updated - df.timestamp_created)\n",
    "t2=np.array(t2)\n",
    "t2=t2.reshape((-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(t2,t1)\n",
    "ypredict=lin_reg.predict(t2)\n",
    "\n",
    "plt.scatter(t2,t1)\n",
    "plt.plot(t2,lin_reg.predict(t2),color='green')\n",
    "plt.title(\"Regression Model\")\n",
    "plt.xlabel(\"Time pass\")\n",
    "plt.ylabel(\"Score\")\n",
    "#bella schifezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('linear regression coefficient=', lin_reg.coef_[0])\n",
    "print('linear regression intercept=', lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "print (\"Coefficient of determination :\",r2_score(t1,ypredict))\n",
    "print (\"MSE: \",mean_squared_error(t1,ypredict))\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(t1,ypredict)))\n",
    "#i commenti li farò meglio a dataset completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value 𝑏₀ = 0.14 (approximately) illustrates that the model predicts the response 0.14 when 𝑥 (time that pass) is zero. The value 𝑏₁ = 1.2e-09 means that the predicted response rises by 𝑏₁ when 𝑥 is increased by one (in this case: the time increases of one \"what??."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any change in the relationship of the variables mentioned in the previous literal if you include whether an application is recommended or not in the review? Use an appropriate statistical test or technique and support your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3=df['recommended'].astype(int)\n",
    "\n",
    "\n",
    "X=np.vstack([t1,t3])\n",
    "X = X.transpose()\n",
    "print(X.shape)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "l_reg=LinearRegression()\n",
    "\n",
    "model=l_reg.fit(X,t1)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "expected = t1\n",
    "predicted = model.predict(X)\n",
    "\n",
    "\n",
    "print('linear regression coefficient=', lin_reg.coef_[0])\n",
    "print('linear regression intercept=', lin_reg.intercept_)\n",
    "from sklearn.metrics import mean_squared_error,r2_score,explained_variance_score\n",
    "print (\"Coefficient of determination :\",r2_score(t1,predict))\n",
    "print (\"MSE: \",mean_squared_error(t1,predict))\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(t1,predict)))\n",
    "#i commenti li farò meglio a dataset completo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are histograms, bar plots, scatterplots and pie charts used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram is visula representation of the distribution of numerical data usually grouped in bins which a non \n",
    "overlapped series of intervals.\n",
    "A bar chart or bar graph is a chart or graph that presents categorical data with rectangular bars with heights \n",
    "or lengths proportional to the values that they represent.\n",
    "A scatter plot uses dots to represent values for two different numeric variables expressing the relationship that \n",
    "occurs between the two variables.\n",
    "A pie chart is a circular graphic method which is used to illustrate numerical proportion into a group of variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What insights can you extract from a Box Plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box-plot is a graphical representation that can be used to describe the distribution of data through 5 indices: the minimum, the maximum, the median (quantile lev=0.5) and the first and third quartiles.\n",
    "The \"box\" is delimited by the first and third quartiles (so the height is the interquantile difference IQR = q3-q1)and divided inside by the median. The \"whiskers\" are delimited by the minimum and maximum of the values. In this way the data is divided into four intervals with the same number of elements and this shows, for example, if the distribution is symmetric or not. Data that does not fit into the \"whiskers\" are called outliers, they are defined as outside the interval [-IQR,+IQR]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For this homework, you are required to work with all data in the steam_reviews.csv. An extension (two files) \n",
    "of the dataset is available in the next links:\n",
    "\n",
    "a. File 1 to be downloaded from https://sapienza2021adm.s3.eu-south-1.amazonaws.com/steam_reviews_bonus_1.zip.\n",
    "\n",
    "b. File 2 to be downloaded from https://sapienza2021adm.s3.eu-south-1.amazonaws.com/steam_reviews_bonus_2.zip.\n",
    "\n",
    "It is not necessary to use the extension for this homework, however, if you decide to use it, we will take it into\n",
    "account in the final evaluation. In summary, to get the bonus points you are required to work with\n",
    "[steam_reviews.csv + two files of extension] all together.\n",
    "''';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are given the following algorithm.\n",
    "\n",
    "Input: \n",
    "    A: array of length n\n",
    "    k: integers between 1 and n\n",
    "    \n",
    "function alg(A, k):\n",
    "  s <-- a random element of A\n",
    "  set L = [all the elements of A with value <= s]\n",
    "  set R = [all the elements of A with value > s]\n",
    "  r = len(L)\n",
    "  if k == r:\n",
    "    return s\n",
    "  else if k < r:  \n",
    "    return alg(L, k)\n",
    "  else:\n",
    "    return alg(R, k - r)\n",
    "''';\n",
    "import random\n",
    "#IMPLEMENTATION\n",
    "'''\n",
    "def alg(A, k):\n",
    "    #s= a random element of A\n",
    "    s=random.choice(A)\n",
    "    print(s)\n",
    "    L = [x for x in A if x<=s]\n",
    "    print('L=',L)\n",
    "    R = [x for x in A if x>s]\n",
    "    print('R=',R)\n",
    "    lung = len(L)\n",
    "    if k == lung:\n",
    "        return s\n",
    "    elif k < lung:  \n",
    "        return alg(L, k)\n",
    "    else:\n",
    "        return alg(R, k - lung)\n",
    "    \n",
    "alg(A,k)\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the algorithm compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorith find the k smallest element in the Array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is asymptotically (i.e., we are asking for big-O complexity) the running time of the algorithm in the worst case, as a function of n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The worst case occurs when s=min(A)  and k=len(A).\n",
    "In this situation: $$\\begin{align}T(n) &= n + T(n-1)\\\\&= n + (n-1) + T(n-2)\\\\&= ...\\\\&=   \\sum_{i=0}^{n}n-i\\\\&= (\\sum_in + \\sum_i i)\\\\&= ...\\\\&= n^2 - n\\\\&=O(n^2) \\end{align}$$\n",
    "\n",
    "There are degenerate cases where we can not guarantees the convergence of the algorithm:\n",
    "$$ \\begin{itemize}\n",
    "    \\ K=0\n",
    "    \\ s=max(A): the probability is almost 0, but we can not exclude this behaviour\n",
    "    \\ the element we are looking is repeated in the array\n",
    "\\end{itemize} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### What is asymptotically the running time of the algorithm in the best case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best case occurs for k=len(L) and the running time is $$ T(n)=1+n+1+1= O(n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The medium running time is $$ O(n) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "You are given the recursive function splitSwap, which accepts an array a, an index i, and a length n.\n",
    "\n",
    "function splitSwap(a, l, n):\n",
    "  if n <= 1:\n",
    "    return\n",
    "  splitSwap(a, l, n/2)\n",
    "  splitSwap(a, l+ n /2, n/2)\n",
    "  swapList(a, l, n)\n",
    "  \n",
    "The subroutine swapList is described here:\n",
    "\n",
    "function swapList(a, l, n):\n",
    "  for i = 0 to n/2:\n",
    "    tmp = a[l + i]\n",
    "    a[l + i] = a[l + n/2 + i]\n",
    "    a[l + n/2 + i] = tmp\n",
    "'''\n",
    "#IMPLEMENTATION\n",
    "\n",
    "\n",
    "def splitSwap(a, l, n, lvl=0):\n",
    "    if n <= 1:\n",
    "        return\n",
    "    indent = '\\t'*lvl\n",
    "    print(f\"{indent}entered at lvl {lvl} with a: {a}\\n\")\n",
    "    splitSwap(a, l, n//2, lvl+1)\n",
    "    splitSwap(a, l+ n//2, n//2, lvl+1)\n",
    "    print(f\"{indent}* a pre_swap: {a}\")\n",
    "    swapList(a, l, n)\n",
    "    print(f\"{indent}* a after_swap: {a}\\n\\n\")\n",
    "\n",
    "def swapList(a, l, n):\n",
    "    for i in range(n//2):\n",
    "        tmp = a[l + i]\n",
    "        a[l + i] = a[l + n//2 + i]\n",
    "        a[l + n//2 + i] = tmp\n",
    "    \n",
    "splitSwap([i for i in range(1,9)], 0, 8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much running time does it take to execute splitSwap(a, 0, n)? (We want a Big O analysis.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alessandro ha il codice latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this algorithm do? Is it optimal? Describe the mechanism of the algorithm in details, we do not want to know only its final result. HINT: Consider the scenario where len(a) and n are numbers that are a power of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The algorith reverse the subarray starting from the index i untill i+n : as the implementation shows, in every\n",
    "level we swap a subarray of dimension 2^(log2(n)-1-level).\n",
    "The algorith is not optimal since we can solve the same problem with an algorith with O(n)=n.\n",
    "For example we can consider another array B in which we store the elements of the Array A from the index l+n untill l \n",
    "( step=-1) and then we could copy the elements of B in the positions l untill l+n of A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def another_algorith(A,l,n):\n",
    "    B=[]\n",
    "    for i in range(l+n,l,-1):\n",
    "        B.append(A[i])\n",
    "    for i in range(l,l+n):\n",
    "        A[i]=B[i-l]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In the knapsack problem we are given n objects and each object i has a weight w_i and a value v_i.\n",
    "We are also given a weight budget W. The problem is to select a set of objects with total weight bounded by W \n",
    "that maximized the sum of their values. The following are three natural heuristics:\n",
    "\n",
    "*Order them in increasing order of weight and then visit them sequentially, adding them to the solution \n",
    "as long as the budget is not exceeded\n",
    "\n",
    "*Order them in decreasing order of values, and then visit them sequentially, adding them to the solution \n",
    "if the budget is not exceeded\n",
    "\n",
    "*Order them in decreasing relative value (v_i / w_i), and then visit them sequentially, adding them to the \n",
    "solution if the budget is not exceeded\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each of the heuristics, provide a counterexample, that is, an example of a problem instance in which the heuristic fails to provide the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the existence of two elements A={p=2,v=2}, B={p=1,v=0} and set the weight budget=W=2.\n",
    "If we order the objects in increasing order of weight and then visit them sequentially, adding them to the solution\n",
    "as long as the budget is not exceeded , we will find {B} with a total value of 0.\n",
    "This is not an optimal solution since the solution given by {A} respects the weight costraint \n",
    "and has a total value of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the existence of three elements A={v=3,p=3},B={v=2,p=1},C={p=1,v=2} and set the weight budget=3.\n",
    "If we order them in decreasing order of values, and then visit them sequentially, adding them to the \n",
    "solution if the budget is not exceeded, we will find {A} with a total value of 3.\n",
    "This is not an optimal solution since the solution given by {B,C} has a total weight of 2 and a total value of 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the existence of two elements A={v=2,p=1,v/p=2}, B={v=3,p=3,v/p=1} and set the weight budget=3.\n",
    "If we order them in decreasing relative value (v_i / w_i), and then visit them sequentially, adding them\n",
    "to the solution if the budget is not exceeded, we will find {A} with a total value of 2.\n",
    "This is not an optimal solution since the solution given by {B} respects the weight costraint \n",
    "and has a total value of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
